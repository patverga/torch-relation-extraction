\section{Appendix}

\subsection{Additional Qualitative Results}

Our model jointly embeds KB relations together with English and Spanish text. We demonstrate that plausible textual patterns are embedded close to the KB relations they express. Table \ref{tab:top-tac-patterns} shows top scoring English and Spanish patterns given sample relations from our TAC KB.

\begin{table}[h]
\begin{center}
\hspace*{-20pt}
\begin{tabular}{|p{8.3cm}|}
\hline
\textbf{per:sibling} \\
\hline
   \argOne, seg\'{u}n petici\'{o}n the primeros ministro, \endgraf \hspace{5pt} su hermano gemelo \argTwo  			\\ %\cline{3-3}
  \argOne, sea the principal favorito para esto oficina \endgraf \hspace{5pt}que tambi\'{e}n ambiciona su hermano \argTwo 	\\%\cline{3-3}
  \argOne, y su hermano gemelo, the primeros ministro \argTwo 	\\
\hline
  \argOne, for whose brother \argTwo  		\\%\cline{3-3}
  \argOne inherited his brother \argTwo 	\\%\cline{3-3}
  \argOne on saxophone and brother \argTwo 	\\
\hline\hline
%
\textbf{org:top\_members\_employees} \\
\hline
   \argTwo, presidente y director generales the \argOne  			\\%\cline{3-3}
   	\argTwo, presidente of the negocios especializada \argOne  	\\%\cline{3-3}
   	\argTwo (CIA), the director of the entidad, \argOne 	\\
\hline
 \argTwo, vice president and policy director of the \argOne  		\\%\cline{3-3}
 \argTwo, president of the German Soccer \argOne 	\\%\cline{3-3}
  \argTwo, president of the quasi-official \argOne 	\\
\hline\hline
%%
\textbf{per:alternate\_names} \\
\hline
   \argOne(como tambi\'{e}n son sabido para \argTwo 			\\%\cline{3-3}
   \argTwo-cuyos verdaderos nombre sea \argOne 	\\%\cline{3-3}
   	\argOne  tambi\'{e}n sabido como \argTwo 	\\
\hline
   \argOne aka \argTwo 		\\%\cline{3-3}
   \argOne, who also creates music under the pseudonym \argTwo 	\\%\cline{3-3}
   \argOne( of Modern Talking fame ) aka \argTwo  	\\
\hline\hline
%%
\textbf{per:cities\_of\_residence} \\
 \hline
  \argOne, poblado d\'{o}nde vive \argTwo 			\\%\cline{3-3}
   \argOne, una ciudadano naturalizado american y nacido in \argTwo 	\\%\cline{3-3}
   \argOne, que vive in \argTwo 	\\
\hline
   \argOne was born Jan. \# , \#\#\#\# in \argTwo 		\\%\cline{3-3}
   	\argOne was born on Monday in \argTwo 	\\%\cline{3-3}
   \argOne was born at Keighley in \argTwo 	\\
\hline
\end{tabular}
\caption{Top scoring patterns for both Spanish (top) and English (bottom) given query TAC relations. \label{tab:top-tac-patterns}}
\end{center}
\end{table}

\subsection{Details Concerning Cosine Similarity Computation}
\label{app:cosine}
We measure the similarity between $r_{\text{text}}$ and $r_{\text{schema}}$ by computing the vectors' cosine similarity. However, such a distance is not well-defined, since the model was trained using inner products between entity vectors and relation vectors, not between two relation vectors. The US likelihood is invariant to invertible transformations of the latent coordinate system, since $\sigma\left( u_{s,o}^\top v_r \right) = \sigma\left( (A^\top u_{s,o})^\top A^{-1} v_r \right)$ for any invertible $A$. When taking inner products between two $v$ terms, however, the implicit $A^{-1}$ terms do not cancel out. We found that this issue can be minimized, and high quality predictive accuracy can be achieved, simply by using sufficient $\ell_2$ regularization to avoid implicitly learning an $A$ that substantially stretches the space.

\subsection{Data Pre-processing, Distant Supervision and Extraction Pipeline \label{sec:ds-el}}

We replace tokens occurring less than 5 times in the corpus with UNK and normalize all digits to \# (e.g. Oct-11-1988 becomes Oct-\#\#-\#\#\#\#).
For each sentence, we then extract all entity pairs and the text between them as surface patterns, ignoring patterns longer than 15 tokens.
This results in 48 million English `relations'. In Section~\ref{sec:norm}, we describe a technique for normalizing the surface patterns.
We filter out entity pairs that occurred less than 10 times in the data and extract the largest connected component in this entity co-occurrence graph.
This is necessary for the baseline US model, as otherwise learning decouples into independent problems per connected component.
Though the components are connected when using sentence encoders, we use only a single component to facilitate a fair comparison between modeling approaches.
We add the distant supervision training facts from the RelationFactory system, i.e. 352,236 entity-pair-relation tuples obtained from Freebase and high precision seed patterns.
The final training data contains a set of 3,980,164 (KB and openIE) facts made up of 549,760 unique entity pairs, 1,285,258 unique relations and 62,841 unique tokens.

We perform the same preprocessing on the Spanish data, resulting in 34 million raw surface patterns between entities.
We then filter patterns that never occur with an entity pair found in the English data.  This yields 860,502 Spanish patterns.
Our multilingual model is trained on a combination of these Spanish patterns, the English surface patterns, and the distant supervision data described above.
We learn word embeddings for 39,912 unique Spanish word types.
After parameter tying for translation pairs (Section \ref{sec:tie-words}),  there are 33,711 additional Spanish words not tied to English.


\subsection{Generation of Cross-Lingual Tied Word Types}
\label{sec:word-tying}
We follow the same procedure for generating translation pairs as \cite{mikolov2013}. First, we select the top 6000 words occurring in the lowercased Europarl dataset for each language and obtain a Google translation. We then filter duplicates and translations resulting in multi-word phrases. We also remove English past participles (ending in -ed) as we found the Google translation interprets these as adjectives (e.g.,  `she read the borrowed book' rather than `she borrowed the book') and much of the relational structure in language we seek to model is captured by verbs. This resulted in 6201 translation pairs that occurred in our text corpus. Though higher quality translation dictionaries would likely improve this technique, our experimental results show that such automatically generated dictionaries perform well.


\subsection{Open IE Pattern Normalization}
\label{sec:norm}
To improve US generalization, our US relations use log-shortened patterns where the middle tokens in patterns longer than five tokens are simplified. For each long pattern we take the first two tokens and last two tokens, and replace all $k$ remaining tokens with the number $\log k$. For example, the pattern {\bf Barack Obama} {\it is married to a person named} {\bf Michelle Obama} would be converted to: {\bf Barack Obama} {\it is married [1] person named} {\bf Michell Obama}. This shortening performs slightly better than whole patterns. LSTM and CNN variants use the entire sequence of tokens.
